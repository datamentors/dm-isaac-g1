# ==============================
# DM-ISAAC-G1 Workstation Dockerfile
# Based on Unitree's official unitree_sim_isaaclab Dockerfile
# https://github.com/unitreerobotics/unitree_sim_isaaclab/blob/main/Dockerfile
#
# TWO-IMAGE STRATEGY:
#   Stage "base"  → dm-workstation-base:latest  (pushed to ECR, stable)
#   Stage "groot" → dm-workstation:latest        (extends base, adds GR00T deps)
#
# Build base only:
#   docker build --target base -t dm-workstation-base:latest .
# Build full (base + groot):
#   docker build --target groot -t dm-workstation:latest .
#
# CUDA Compatibility:
#   Workstation driver: 590.48.01 (CUDA 13.1 max)
#   CUDA toolkit in image: 12.8.0
#   Builder base: cuda:12.8.0-devel (has nvcc for compiling flash-attn + extensions)
#   Runtime base: cuda:12.8.0-runtime (leaner, no nvcc needed at runtime)
#   PyTorch build: cu128 — the correct index for PyTorch 2.7.x per
#     https://pytorch.org/get-started/previous-versions/
#   Isaac Sim 5.0.0: installed via pip from pypi.nvidia.com
# ==============================

# ==============================
# Stage 1: Builder
# Heavy compilation happens here; artifacts copied to final stages.
# Uses devel image (not runtime) so nvcc is available for building
# flash-attn and other CUDA extension wheels.
# ==============================
FROM nvidia/cuda:12.8.0-devel-ubuntu22.04 AS builder

ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC
ENV CONDA_DIR=/opt/conda
ENV PATH=$CONDA_DIR/bin:$PATH

# Build dependencies (GCC 12 + GLU + Vulkan + cmake)
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc-12 g++-12 cmake build-essential unzip git git-lfs \
    libglu1-mesa-dev vulkan-tools wget ca-certificates \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 100 \
    && update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 100 \
    && rm -rf /var/lib/apt/lists/*

# Install Miniconda
RUN wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh && \
    bash miniconda.sh -b -p $CONDA_DIR && \
    rm miniconda.sh && \
    $CONDA_DIR/bin/conda clean -afy

# Accept Conda TOS and create Python 3.11 environment
RUN conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main && \
    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r && \
    conda create -n unitree_sim_env python=3.11 -y && \
    conda clean -afy

SHELL ["conda", "run", "-n", "unitree_sim_env", "/bin/bash", "-c"]

# ABI-compatible libgcc/libstdc++ for compiled wheels
RUN conda install -y -c conda-forge "libgcc-ng>=12" "libstdcxx-ng>=12" && \
    apt-get update && apt-get install -y --no-install-recommends libvulkan1 vulkan-tools \
    && rm -rf /var/lib/apt/lists/*

# PyTorch 2.7.0 cu128 — CUDA 12.8 is the correct index for PyTorch 2.7.x
# per https://pytorch.org/get-started/previous-versions/
# Workstation driver 590.48.01 supports CUDA 13.1, fully compatible with cu128.
RUN pip install --upgrade pip uv && \
    pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 \
        --index-url https://download.pytorch.org/whl/cu128

# Isaac Sim 5.0.0 via pip (Unitree-approved approach)
# numpy pinned <2.0: Isaac Sim synthetic data pipeline requires numpy 1.x
RUN pip install "isaacsim[all,extscache]==5.0.0" --extra-index-url https://pypi.nvidia.com && \
    pip install "numpy>=1.26.0,<2.0.0" --force-reinstall

WORKDIR /home/code

# IsaacLab v2.2.0 (compatible with Isaac Sim 5.0.0 per Unitree docs)
RUN git clone https://github.com/isaac-sim/IsaacLab.git && \
    cd IsaacLab && \
    git checkout v2.2.0 && \
    ./isaaclab.sh --install

# CycloneDDS — required by unitree_sdk2_python
RUN git clone https://github.com/eclipse-cyclonedds/cyclonedds -b releases/0.10.x /cyclonedds && \
    cd /cyclonedds && mkdir build install && cd build && \
    cmake .. -DCMAKE_INSTALL_PREFIX=../install && \
    cmake --build . --target install -j$(nproc)

ENV CYCLONEDDS_HOME=/cyclonedds/install

# unitree_sdk2_python — robot SDK
RUN git clone https://github.com/unitreerobotics/unitree_sdk2_python && \
    cd unitree_sdk2_python && pip install -e .

# unitree_sim_isaaclab — USD assets, G1 task definitions, pink/pinocchio IK
RUN git clone https://github.com/unitreerobotics/unitree_sim_isaaclab.git /home/code/unitree_sim_isaaclab && \
    cd /home/code/unitree_sim_isaaclab && pip install -r requirements.txt

# pink + pinocchio — IK libraries for G1 manipulation scenes
# Installed in builder so both base and groot inherit them.
# No assimp conflict in this conda env (DEVOPS-001 resolved).
# Re-pin numpy <2.0 after pinocchio deps pull numpy 2.x.
RUN pip install pin-pink meshcat && \
    pip install "numpy>=1.26.0,<2.0.0" --force-reinstall

# flatdict — required by isaaclab.sim.simulation_context (isaaclab dep, not auto-installed).
# Without this, Isaac Sim crashes during extension startup with:
#   ModuleNotFoundError: No module named 'flatdict'
# flatdict 4.1.0 is functionally compatible with isaaclab's pinned 4.0.1 requirement.
RUN pip install flatdict

# ==============================
# Stage 2: base — stable image pushed to ECR
# Isaac Sim + IsaacLab + unitree stack, NO GR00T
# ==============================
FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04 AS base

ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC
ENV CONDA_DIR=/opt/conda
ENV PATH=$CONDA_DIR/bin:$PATH
ENV OMNI_KIT_ALLOW_ROOT=1
ENV ACCEPT_EULA=Y
# Correct env var that isaacsim pip package checks to skip interactive EULA
ENV OMNI_KIT_ACCEPT_EULA=Y

# Runtime system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    libglu1-mesa git git-lfs curl wget \
    zenity unzip vim htop tmux \
    xorg libxext6 libxrender1 libxtst6 libxi6 \
    libglib2.0-0 libvulkan1 vulkan-tools \
    ncurses-term dbus-x11 \
    xfce4 xfce4-terminal xfce4-taskmanager \
    && rm -rf /var/lib/apt/lists/*

# Google Chrome — required for AWS SSO authentication in the browser
# Installed via official Google apt repo for latest stable release.
RUN curl -fsSL https://dl.google.com/linux/linux_signing_key.pub \
        | gpg --dearmor -o /usr/share/keyrings/google-chrome.gpg && \
    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome.gpg] \
        https://dl.google.com/linux/chrome/deb/ stable main" \
        > /etc/apt/sources.list.d/google-chrome.list && \
    apt-get update && apt-get install -y --no-install-recommends google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# TurboVNC — remote visualization for Isaac Sim
RUN wget -q https://github.com/TurboVNC/turbovnc/releases/download/3.1.2/turbovnc_3.1.2_amd64.deb \
        -O /tmp/turbovnc.deb && \
    dpkg -i /tmp/turbovnc.deb || apt-get install -f -y && \
    rm /tmp/turbovnc.deb
ENV PATH="/opt/TurboVNC/bin:${PATH}"

# VNC: set password (max 8 chars) and use XFCE4 as the desktop session.
# TVNC_WM=xfce maps to /usr/share/xsessions/xfce.desktop → startxfce4.
ENV TVNC_WM=xfce
RUN mkdir -p ~/.vnc && \
    printf "datament\ndatament\nn\n" | /opt/TurboVNC/bin/vncpasswd

# Copy all artifacts from builder
COPY --from=builder /home/code/IsaacLab            /home/code/IsaacLab
COPY --from=builder /home/code/unitree_sdk2_python  /home/code/unitree_sdk2_python
COPY --from=builder /home/code/unitree_sim_isaaclab /home/code/unitree_sim_isaaclab
COPY --from=builder /cyclonedds                     /cyclonedds
COPY --from=builder /opt/conda                      /opt/conda

ENV CYCLONEDDS_HOME=/cyclonedds/install
ENV LD_LIBRARY_PATH="${CYCLONEDDS_HOME}/lib:${LD_LIBRARY_PATH}"

# PROJECT_ROOT — required by unitree_sim_isaaclab scene configs to locate USD assets.
# Without this, scenes crash with:
#   FileNotFoundError: USD file not found at path 'None/assets/objects/PackingTable/PackingTable.usd'
# The scene configs use: project_root = os.environ.get("PROJECT_ROOT")
# At runtime /workspace/unitree_sim_isaaclab is mounted from host (contains the assets).
# At image build time the same scenes are at /home/code/unitree_sim_isaaclab.
# We set /workspace/... because the mount path is what's used at runtime.
ENV PROJECT_ROOT=/workspace/unitree_sim_isaaclab

# PYTHONPATH: dm-isaac-g1 and Isaac-GR00T are mounted at runtime
# unitree_sim_isaaclab path covers the G1 scene configs and USD references
ENV PYTHONPATH="/workspace/dm-isaac-g1/src:/workspace/Isaac-GR00T:/home/code/IsaacLab/source/isaaclab:/home/code/IsaacLab/source/isaaclab_tasks:/home/code/IsaacLab/source/isaaclab_rl:/home/code/IsaacLab/source/isaaclab_assets:/home/code/IsaacLab/source/isaaclab_contrib:/home/code/unitree_sim_isaaclab:${PYTHONPATH}"

RUN echo 'source /opt/conda/etc/profile.d/conda.sh' >> ~/.bashrc && \
    echo 'conda activate unitree_sim_env' >> ~/.bashrc && \
    echo 'export OMNI_KIT_ALLOW_ROOT=1' >> ~/.bashrc && \
    echo 'export ACCEPT_EULA=Y' >> ~/.bashrc && \
    echo 'export OMNI_KIT_ACCEPT_EULA=Y' >> ~/.bashrc && \
    echo 'export CYCLONEDDS_HOME=/cyclonedds/install' >> ~/.bashrc && \
    echo 'export LD_LIBRARY_PATH=/cyclonedds/install/lib:$LD_LIBRARY_PATH' >> ~/.bashrc

EXPOSE 47995-48012
EXPOSE 49000-49007
EXPOSE 6006
EXPOSE 5555
EXPOSE 5901

WORKDIR /home/code
CMD ["conda", "run", "--no-capture-output", "-n", "unitree_sim_env", "/bin/bash"]

# ==============================
# Stage 3: groot — extends base with GR00T inference + fine-tuning deps
# This is the image used for inference and fine-tuning with GROOT.
#
# LIBRARY MANAGEMENT RULES — MANDATORY:
#   1. ALL Python packages MUST be installed via:  uv pip install --system <pkg>
#      Never use bare `pip install` or `conda install` for Python packages.
#   2. conda install is ONLY permitted for non-Python system libraries
#      (e.g. conda-forge ffmpeg for shared .so files). Add a comment explaining why.
#   3. NO library version change may be made without explicit written approval.
#      If a version change is needed, open a PR and get it reviewed first.
#   4. All new dependencies MUST be added to requirements-groot.txt with exact
#      pinned versions before being added to this Dockerfile.
#   5. The Dockerfile is the single source of truth. Any package installed on the
#      workstation manually must be reflected here before the next Docker build.
#
# GR00T extra deps (on top of what Isaac Sim + IsaacLab already provide):
#   - albumentations, av, diffusers, dm-tree, lmdb, msgpack, msgpack-numpy
#   - peft, termcolor, tyro, datasets, gymnasium, omegaconf, pyzmq
#   - deepspeed, wandb, einops, click, pandas, scipy
#   - transformers==4.51.3 (GR00T's exact pin — DO NOT change without approval)
#   - flash-attn: required by Eagle3_VL backbone for fine-tuning on CUDA 12.8.
#     Built via uv pip install --system with --no-build-isolation (needs nvcc).
#   - torchcodec==0.4.0+cu128: AV1-capable video decoder for LeRobot v3.0 datasets.
#     Must be installed AFTER conda-forge ffmpeg (for libavutil.so shared libs).
# ==============================
FROM base AS groot

SHELL ["conda", "run", "-n", "unitree_sim_env", "/bin/bash", "-c"]

# Install uv — the ONLY approved Python package manager for this image.
# uv is installed via pip once to bootstrap itself, then all subsequent
# package installs MUST use: uv pip install --system <package>
RUN pip install uv

# Copy the groot requirements file
COPY requirements-groot.txt /tmp/requirements-groot.txt

# Install GR00T extra deps via uv
# The SHELL directive above already runs inside unitree_sim_env so
# uv picks up the active python directly — no --python flag needed.
# --system allows uv to install into the conda env's site-packages.
RUN uv pip install --system -r /tmp/requirements-groot.txt

# flash-attn: built from source against PyTorch 2.7.0 + CUDA 12.8.
# The base runtime image does not include nvcc, so we install cuda-nvcc
# just for the compilation step. --no-build-isolation ensures it uses the
# already-installed torch. The nvcc install adds ~500MB to this layer but
# enables efficient attention for Eagle3_VL during GR00T fine-tuning.
# If flash-attn is absent the model falls back to eager attention (slower, more VRAM).
RUN apt-get update && apt-get install -y --no-install-recommends cuda-nvcc-12-8 \
    && rm -rf /var/lib/apt/lists/* \
    && uv pip install --system flash-attn --no-build-isolation

# conda-forge FFmpeg: provides libavutil.so.5x shared libs required by torchcodec.
# The system FFmpeg in ubuntu22.04 doesn't expose these versioned .so files.
# NOTE: conda install is used here ONLY because this installs native shared libraries
# (.so files), not Python packages. This is the ONLY permitted use of conda install
# in this stage. Python packages must always use: uv pip install --system
RUN conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main && \
    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r && \
    conda install -n unitree_sim_env -c conda-forge ffmpeg -y

# torchcodec: AV1-capable video decoder required for LeRobot v3.0 datasets
# (HuggingFace Dex3 and other recent datasets use AV1 codec in MP4 containers).
# Must be installed AFTER conda-forge ffmpeg to find the correct libavutil.so.
# cu128 wheel is ABI-matched to PyTorch 2.7.0+cu128 (avoids symbol mismatch).
# Version 0.4.0 is pinned — DO NOT upgrade without testing ABI compatibility.
RUN uv pip install --system torchcodec==0.4.0 --index-url https://download.pytorch.org/whl/cu128

WORKDIR /home/code
CMD ["conda", "run", "--no-capture-output", "-n", "unitree_sim_env", "/bin/bash"]
